{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ////////////////////////////////////\n",
    "##### /// Bias And Variance: Intuition\n",
    "##### ////////////////////////////////////\n",
    "- Let's assume that we want to get the relationship between the employee salary (y) and number of years of Experience (X)\n",
    "- Fresh graduates tend to have low salaries\n",
    "- As years of experience increase, the salaries tend to increase as well.\n",
    "- As number of years go beyond a certain limit, salaries tend to plateau and they do not increase anymore.\n",
    "<br><br>\n",
    "- what we want to do is we want to Build a Regression Model that can model the Relationship, between numbers of years of Experience and Salary.\n",
    "<br><br>\n",
    "\n",
    "- What we could do is say this is my Perfect Model the Perfect model would look like this\n",
    "<img src=\"./assets/3-/1-Bias Variance Intuition 2.png\" width=\"400px\" />\n",
    "\n",
    "<br>\n",
    "- If i Train a Linear Regression or a Polynomial Model, and the model was able to give me the Exact relationship (prev image), that would be Perfect that would be the True Model, the Best Model Ever.\n",
    "<br>\n",
    "##### /// Let's take a Look into 2 Models In Order to Explain Bias and Variance Trade-off\n",
    "* Model #1: that will be a Simple Linear Regression, 1 Straight line and this line is very rigged (can't bend it, can't increase the Order of Polynomial)<br>\n",
    "* Model #2: Complex Model it will be 10th Order Polynomial, i can bend it more-ever i want it has more Flexibility Built into it.\n",
    "<br><br>\n",
    "- Linear Regression model uses a straight line to fit the training dataset\n",
    "<img src=\"./assets/3-/4- model 1.png\" width=\"500px\"/>\n",
    "* you can see this Line is OK it provides an OK Accuracy or an OK Fit.\n",
    "<br><br>\n",
    "- Linear regression model lacks Flexibility so it cannot properly fit the data (as the true perfect model does)<br>\n",
    "* Because we can't bend it to have the Perfect Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ///////////////////////\n",
    "###### /// BIAS\n",
    "###### ///////////////////////\n",
    "<img src=\"./assets/4-/7-models 1.png\" />\n",
    "<br><br>\n",
    "- The linear model has a large \"bias\" which indicates that the model is unable to accurately capture the true relationship between salary and Years of Experience.\n",
    "* This line has a Large Bias \n",
    "* When you have a model that does not Capture the True values or the True Fit Within the Training Data, We call this Fit has a Large Bias.\n",
    "\n",
    "<br><br>\n",
    "Model #2: High Order Polynomial Regression (Complex)\n",
    "* Let's Assume that we have the Exact same Example, and we have our Perfect Model,\n",
    "but this time we're gonna use Model 2, Model 2 Has High Order Polynomial Regression\n",
    "* now i can Bend it whenever i want \n",
    "\n",
    "- High order Polynomial model is able to have a very small bias and can Perfectly fit the training dataset.\n",
    "* as you can see it has a Very small Bias, which means it's Very Flexible and was able to Capture all the Variations within the data which is Perfect\n",
    "- High-order Polynomial model is very Flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ///////////////////////\n",
    "###### /// Models Summary\n",
    "###### ///////////////////////\n",
    "- Model 1 : Is Linear Regression Very Simple and it has a Very Large Bias, Why ?\n",
    "Because It doesn't Perfectly fit the Data Points\n",
    "<br><br>\n",
    "- Model 2 : From Outside a Perfect Model that Can Fit Every Single data point, it's what we call Overfitting the data, \n",
    "Understanding Every single detail within the model, we call this it has a Very Small Bias\n",
    "<br><br>\n",
    "Look at the Other Aspect of the Story (Model 1)\n",
    "###### /// Model 1 VS. Model 2\n",
    "- by compering these 2 model #2 looks great \n",
    "the sum of Squares looks very small for model 2\n",
    "and if you look at model 1 you see that Sum of SQuares if Very Large\n",
    "<br><br>\n",
    "###### /// The Problem (7-models 2)\n",
    "<img src=\"./assets/4-/7-models 2.png\" />\n",
    "this is not the Whole story,\n",
    "if you look at the Exact same models but instead of Relying on Training Data,\n",
    "<br><br>\n",
    "we're going to rely on Testing data (model have never seen Before Red points) \n",
    "and you Find the Story Changes Completely.\n",
    "- on Linear Regression Model:\n",
    "* there will be an Error, but this Error is Ok it's very Compareable to the Error we had during Training\n",
    "<br><br>\n",
    "- For Polynomial Model:\n",
    "the results will be Horrible, because this Model was able to Capture all the Details all the features of the training data set,\n",
    "however when we change that to testing dataset the results are terrible why ?\n",
    "because this model is what we call Overfit model, means the model works great  on training data only (and fails miserably in testing)\n",
    "<br><br>\n",
    "- based on this during testing you'll find the Linear Regression Model is better compared to the Polynomial Model\n",
    "- if you calculated sum of Squares you'll find it small in Linear Regression and Large in Polynomial Regression Model \n",
    "\n",
    "* Polynomial Model performs poorly on the testing dataset and therefore it has large variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### /////////////////////////\n",
    "##### /// Variance\n",
    "##### /////////////////////////\n",
    "- simply when we say variance, a model has a Large Variance that means it has a Larger variability when it comes to results, so when it has different Performance on 2 different datasets, during training it Performers something, and during testing it Performers something\n",
    "<br><br>\n",
    "- as you can see the LR model has a very small variance because the results are pretty much the same (training & testing), the results are not very great by Ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ///////////////////////////////\n",
    "##### /// Model Complexity vs Error\n",
    "##### ///////////////////////////////\n",
    "- Regularization works by reducing the variance at the cost of adding some bias to the model.\n",
    "* we're gonna cover Ridge and Lasso Regression techniques to overcome this Issue\n",
    "- A trade-off between variance and bias is needed.\n",
    "\n",
    "<br><br>\n",
    "- Image\n",
    "<img src=\"./assets/4-/8-model Complexity 1.png\" height=\"100px\" />\n",
    "- as you can see let's assume that on the X Axis the Model Complexity, <br>we're gonna assume Linear a Very Simple Model and as we move to the right we're gonna have more Complex model it might be Polynomial or (ANN), <br>and on Y Axis we have Error Signal.\n",
    "- as you can see if we have a simple Linear Model the Bias is gonna be Large why ?:\n",
    "    because the model is Rigged and it can't capture all the Variations within the model or the Training data.\n",
    "- but as we increase the Complexity of the Model the Bias will go down, the model becomes more Flexible & more smart,\n",
    "    you can change fit of the model to exactly fit our training data   \n",
    "<br><br>\n",
    "- however if we have a Linear Model we're gonna have an OK Variance (small variance), <br> which means the Performance of the Model during training is gonna match Performance of the Model during Testing.\n",
    "- as we increase the Complexity of the Model the model starts to Over-fit way more, <br> that's why you find variance goes up which means the model losses generality (losses generalization capability) br>  so the variance will go up \n",
    "<br>\n",
    "//// <b>Important Concept in ML</b>\n",
    "- Bias Variance Trade-off\n",
    "- so now i need to find the Sweet spot\n",
    "- i need to find a point where there is some Variance, there is some bias but they are minimized,<br> i don't need a model that does great during training and performance Poorly during testing and vice verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
